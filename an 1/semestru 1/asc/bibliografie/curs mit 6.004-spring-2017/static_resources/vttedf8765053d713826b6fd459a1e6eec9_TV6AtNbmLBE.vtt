WEBVTT

00:00:00.960 --> 00:00:03.590
Okay, let's review our plan.

00:00:03.590 --> 00:00:07.730
The processor starts an access by sending
an address to the cache.

00:00:07.730 --> 00:00:12.719
If data for the requested address is held
in the cache, it's quickly returned to the

00:00:12.719 --> 00:00:13.830
CPU.

00:00:13.830 --> 00:00:18.930
If the data we request is not in the cache,
we have a cache miss, so the cache has to

00:00:18.930 --> 00:00:24.759
make a request to main memory to get the data,
which it then returns to processor.

00:00:24.759 --> 00:00:29.289
Typically the cache will remember the newly
fetched data, possibly replacing some older

00:00:29.289 --> 00:00:30.960
data in the cache.

00:00:30.960 --> 00:00:36.429
Suppose a cache access takes 4 ns and a main
memory access takes 40 ns.

00:00:36.429 --> 00:00:42.429
Then an access that hits in the cache has
a latency of 4 ns, but an access that misses

00:00:42.429 --> 00:00:46.820
in the cache has a latency of 44 ns.

00:00:46.820 --> 00:00:52.039
The processor has to deal with the variable
memory access time, perhaps by simply waiting

00:00:52.039 --> 00:00:57.010
for the access to complete, or, in modern
hyper-threaded processors, it might execute

00:00:57.010 --> 00:01:00.539
an instruction or two from another programming
thread.

00:01:00.539 --> 00:01:05.550
The hit and miss ratios tell us the fraction
of accesses which are cache hits and the fraction

00:01:05.550 --> 00:01:07.740
of accesses which are cache misses.

00:01:07.740 --> 00:01:12.100
Of course, the ratios will sum to 1.

00:01:12.100 --> 00:01:15.869
Using these metrics we can compute the average
memory access time (AMAT).

00:01:15.869 --> 00:01:20.140
Since we always check in the cache first,
every access includes the cache access time

00:01:20.140 --> 00:01:21.850
(called the hit time).

00:01:21.850 --> 00:01:26.750
If we miss in the cache, we have to take the
additional time needed to access main memory

00:01:26.750 --> 00:01:29.200
(called the miss penalty).

00:01:29.200 --> 00:01:34.049
But the main memory access only happens on
some fraction of the accesses: the miss ratio

00:01:34.049 --> 00:01:37.240
tells us how often that occurs.

00:01:37.240 --> 00:01:42.770
So the AMAT can be computed using the formula
shown here.

00:01:42.770 --> 00:01:47.780
The lower the miss ratio (or, equivalently,
the higher the hit ratio), the smaller the

00:01:47.780 --> 00:01:49.908
average access time.

00:01:49.908 --> 00:01:54.158
Our design goal for the cache is to achieve
a high hit ratio.

00:01:54.158 --> 00:01:58.420
If we have multiple levels of cache, we can
apply the formula recursively to calculate

00:01:58.420 --> 00:02:03.020
the AMAT at each level of the memory.

00:02:03.020 --> 00:02:09.250
Each successive level of the cache is slower,
i.e., has a longer hit time, which is offset

00:02:09.250 --> 00:02:14.020
by lower miss ratio because of its increased
size.

00:02:14.020 --> 00:02:15.770
Let's try out some numbers.

00:02:15.770 --> 00:02:22.079
Suppose the cache takes 4 processor cycles
to respond, and main memory takes 100 cycles.

00:02:22.079 --> 00:02:26.470
Without the cache, each memory access would
take 100 cycles.

00:02:26.470 --> 00:02:33.870
With the cache, a cache hit takes 4 cycles,
and a cache miss takes 104 cycles.

00:02:33.870 --> 00:02:40.940
What hit ratio is needed to so that the AMAT
with the cache is 100 cycles, the break-even

00:02:40.940 --> 00:02:43.050
point?

00:02:43.050 --> 00:02:48.370
Using the AMAT formula from the previously
slide, we see that we only need a hit ratio

00:02:48.370 --> 00:02:54.810
of 4% in order for memory system of the Cache
+ Main Memory to perform as well as Main Memory

00:02:54.810 --> 00:02:56.310
alone.

00:02:56.310 --> 00:03:00.940
The idea, of course, is that we'll be able
to do much better than that.

00:03:00.940 --> 00:03:05.850
Suppose we wanted an AMAT of 5 cycles.

00:03:05.850 --> 00:03:09.730
Clearly most of the accesses would have to
be cache hits.

00:03:09.730 --> 00:03:15.340
We can use the AMAT formula to compute the
necessary hit ratio.

00:03:15.340 --> 00:03:20.180
Working through the arithmetic we see that
99% of the accesses must be cache hits in

00:03:20.180 --> 00:03:25.030
order to achieve an average access time of
5 cycles.

00:03:25.030 --> 00:03:28.840
Could we expect to do that well when running
actual programs?

00:03:28.840 --> 00:03:31.420
Happily, we can come close.

00:03:31.420 --> 00:03:38.060
In a simulation of the Spec CPU2000 Benchmark,
the hit ratio for a standard-size level 1

00:03:38.060 --> 00:03:43.470
cache was measured to be 97.5% over some ~10
trillion accesses.

00:03:43.470 --> 00:03:44.730
[See the "All benchmarks" arithmetic-mean
table at http://research.cs.wisc.edu/multifacet/misc/spec2000cache-data/]

00:03:44.730 --> 00:03:46.870
Here's a start at building a cache.

00:03:46.870 --> 00:03:50.380
The cache will hold many different blocks
of data.

00:03:50.380 --> 00:03:54.700
For now let's assume each block is an individual
memory location.

00:03:54.700 --> 00:03:58.010
Each data block is "tagged" with its address.

00:03:58.010 --> 00:04:04.530
A combination of a data block and its associated
address tag is called a cache line.

00:04:04.530 --> 00:04:09.480
When an address is received from the CPU,
we'll search the cache looking for a block

00:04:09.480 --> 00:04:12.230
with a matching address tag.

00:04:12.230 --> 00:04:16.470
If we find a matching address tag, we have
a cache hit.

00:04:16.470 --> 00:04:20.519
On a read access, we'll return the data from
the matching cache line.

00:04:20.519 --> 00:04:25.791
On a write access, we'll update the data stored
in the cache line and, at some point, update

00:04:25.791 --> 00:04:29.879
the corresponding location in main memory.

00:04:29.879 --> 00:04:34.150
If no matching tag is found, we have a cache
miss.

00:04:34.150 --> 00:04:38.630
So we'll have to choose a cache line to use
to hold the requested data, which means that

00:04:38.630 --> 00:04:44.569
some previously cached location will no longer
be found in the cache.

00:04:44.569 --> 00:04:49.629
For a read operation, we'll fetch the requested
data from main memory, add it to the cache

00:04:49.629 --> 00:04:55.130
(updating the tag and data fields of the cache
line) and, of course, return the data to the

00:04:55.130 --> 00:04:57.000
CPU.

00:04:57.000 --> 00:05:02.379
On a write, we'll update the tag and data
in the selected cache line and, at some point,

00:05:02.379 --> 00:05:05.749
update the corresponding location in main
memory.

00:05:05.749 --> 00:05:11.280
So the contents of the cache is determined
by the memory requests made by the CPU.

00:05:11.280 --> 00:05:17.090
If the CPU requests a recently-used address,
chances are good the data will still be in

00:05:17.090 --> 00:05:21.759
the cache from the previous access to the
same location.

00:05:21.759 --> 00:05:27.539
As the working set slowly changes, the cache
contents will be updated as needed.

00:05:27.539 --> 00:05:32.999
If the entire working set can fit into the
cache, most of the requests will be hits and

00:05:32.999 --> 00:05:37.639
the AMAT will be close to the cache access
time.

00:05:37.639 --> 00:05:40.490
So far, so good!

00:05:40.490 --> 00:05:46.189
Of course, we'll need to figure how to quickly
search the cache, i.e., we'll a need fast

00:05:46.189 --> 00:05:52.409
way to answer the question of whether a particular
address tag can be found in some cache line.

00:05:52.409 --> 00:05:53.490
That's our next topic.